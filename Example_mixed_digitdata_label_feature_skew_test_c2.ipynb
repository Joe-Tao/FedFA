{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d48d9c-412f-4455-8956-09c2670349f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "This experiment seting is following FedBN (this paper url={https://openreview.net/pdf?id=6YEQUn0QICG}).\n",
    "Code souce of data process: https://github.com/med-air/FedBN\n",
    "\n",
    "Before running the this file, due to the requirement of maximum file size of Supplementary Material,\n",
    "please download the pre-processed datasets from following url (sorry for this inconvenience):\n",
    "    https://drive.google.com/uc?export=download&id=1moBE_ASD5vIOaU8ZHm_Nsj0KAfX5T0Sf\n",
    "    \n",
    "and unzip it under 'data/mixed_digit_dataset' directory,\n",
    "then you can start following experiments on mixed-digit dataset.\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa2806-878f-4719-9331-e5b90c62ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import random, os\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "\n",
    "from fedlab.utils.dataset.partition import CIFAR10Partitioner\n",
    "from fedlab.utils.dataset import FMNISTPartitioner\n",
    "from fedlab.utils.functional import partition_report, save_dict\n",
    "    \n",
    "from args_mixed_digit_c2 import args_parser\n",
    "import server_se1 as server\n",
    "import model\n",
    "\n",
    "from utils.global_test import *\n",
    "from utils.local_test import test_on_localdataset\n",
    "from utils.femnist_dataset import *\n",
    "from utils.training_loss import train_loss_show,train_localacc_show\n",
    "from utils.sampling import *\n",
    "from utils.mixed_digits_data_preprocess import *\n",
    "from utils.clusteror import cluster_clients\n",
    "from utils.compute_histogram import compute_histogram, compute_histogram_mixed_digit\n",
    "\n",
    "\n",
    "args = args_parser()\n",
    "\n",
    "def seed_torch(seed=args.seed):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)  \n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()\n",
    "GLOBAL_SEED = 1\n",
    "def worker_init_fn(worker_id):\n",
    "    global GLOBAL_WORKER_ID\n",
    "    GLOBAL_WORKER_ID = worker_id\n",
    "    set_seed(GLOBAL_SEED + worker_id)\n",
    "\n",
    "similarity = False\n",
    "save_models = False\n",
    "Train_model = True\n",
    "C = \"3CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31dcbe-46bf-44e1-aaa4-fd35f186b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = args.num_classes\n",
    "num_clients = args.K\n",
    "number_perclass = args.num_perclass\n",
    " \n",
    "\n",
    "col_names = [f\"class{i}\" for i in range(num_classes)]\n",
    "print(col_names)\n",
    "hist_color = '#4169E1'\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4a9c6-784d-491f-965e-becf4e826d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, data_path, channels, percent=0.1, filename=None, train=True, transform=None):\n",
    "        if filename is None:\n",
    "            if train:\n",
    "                if percent >= 0.1:\n",
    "                    for part in range(int(percent*10)):\n",
    "                        if part == 0:\n",
    "                            self.images, self.targets = np.load(os.path.join(data_path, 'partitions/train_part{}.pkl'.format(part)), allow_pickle=True)\n",
    "                        else:\n",
    "                            images, targets = np.load(os.path.join(data_path, 'partitions/train_part{}.pkl'.format(part)), allow_pickle=True)\n",
    "                            self.images = np.concatenate([self.images,images], axis=0)\n",
    "                            self.targets = np.concatenate([self.targets,targets], axis=0)\n",
    "                else:\n",
    "                    self.images, self.targets = np.load(os.path.join(data_path, 'partitions/train_part0.pkl'), allow_pickle=True)\n",
    "                    data_len = int(self.images.shape[0] * percent*10)\n",
    "                    self.images = self.images[:data_len]\n",
    "                    self.targets = self.targets[:data_len]\n",
    "            else:\n",
    "                self.images, self.targets = np.load(os.path.join(data_path, 'test.pkl'), allow_pickle=True)\n",
    "        else:\n",
    "            self.images, self.targets = np.load(os.path.join(data_path, filename), allow_pickle=True)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.channels = channels\n",
    "        self.targets = self.targets.astype(np.compat.long).squeeze()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "        if self.channels == 1:\n",
    "            image = Image.fromarray(image, mode='L')\n",
    "        elif self.channels == 3:\n",
    "            image = Image.fromarray(image, mode='RGB')\n",
    "        else:\n",
    "            raise ValueError(\"{} channel is not allowed.\".format(self.channels))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577d08d-da76-477b-ac6b-0ebca502e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset_IID(Dataset):\n",
    "    def __init__(self, data_path_list, channels_list, filename=None, transform_list=None, train =True):\n",
    "        \n",
    "        self.transform_list = transform_list\n",
    "        self.channels_list = channels_list\n",
    "        self.images = []\n",
    "        \n",
    "        for index, data_path in enumerate(data_path_list):\n",
    "            if train:\n",
    "                for part in range(10):\n",
    "                    images, targets = np.load(os.path.join(data_path, 'partitions/train_part{}.pkl'.format(part)), allow_pickle=True)\n",
    "                    for k, image in enumerate(images):\n",
    "                        if self.channels_list[index] == 1:\n",
    "                            a = Image.fromarray(image, mode='L')\n",
    "                            a = self.transform_list[index](a)\n",
    "                            self.images.extend(torch.unsqueeze(a, dim=0))\n",
    "                        elif self.channels_list[index] == 3:\n",
    "                            a = Image.fromarray(image, mode='RGB')\n",
    "                            a = self.transform_list[index](a)\n",
    "                            self.images.extend(torch.unsqueeze(a, dim=0))\n",
    "                        else:\n",
    "                            raise ValueError(\"{} channel is not allowed.\".format(self.channels_list[index]))\n",
    "                    if part == 0 and index ==0:\n",
    "                        self.targets = targets\n",
    "                    else:\n",
    "                        self.targets = np.concatenate([self.targets,targets], axis=0)\n",
    "            else:\n",
    "                images, targets = np.load(os.path.join(data_path, 'test.pkl'), allow_pickle=True)\n",
    "                for k, image in enumerate(images):\n",
    "                    if self.channels_list[index] == 1:\n",
    "                        a = Image.fromarray(image, mode='L')\n",
    "                        a = self.transform_list[index](a)\n",
    "                        self.images.extend(torch.unsqueeze(a, dim=0))\n",
    "                    elif self.channels_list[index] == 3:\n",
    "                        a = Image.fromarray(image, mode='RGB')\n",
    "                        a = self.transform_list[index](a)\n",
    "                        self.images.extend(torch.unsqueeze(a, dim=0))\n",
    "                    else:\n",
    "                        raise ValueError(\"{} channel is not allowed.\".format(self.channels_list[index]))\n",
    "                if index ==0:\n",
    "                    self.targets = targets\n",
    "                else:\n",
    "                    self.targets = np.concatenate([self.targets,targets], axis=0)\n",
    "                    \n",
    "        self.targets = self.targets.astype(np.compat.long).squeeze()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "        # if self.channels == 1:\n",
    "        #     image = Image.fromarray(image, mode='L')\n",
    "        # elif self.channels == 3:\n",
    "        #     image = Image.fromarray(image, mode='RGB')\n",
    "        # else:\n",
    "        #     raise ValueError(\"{} channel is not allowed.\".format(self.channels))\n",
    "\n",
    "        # if self.transform is not None:\n",
    "        #     image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d4a95-fa88-4ff5-8171-c36a06619aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_mnist = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "transform_svhn = transforms.Compose([\n",
    "        transforms.Resize([28,28]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "transform_usps = transforms.Compose([\n",
    "        transforms.Resize([28,28]),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "transform_synth = transforms.Compose([\n",
    "        transforms.Resize([28,28]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "transform_mnistm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "percent = 1\n",
    "# MNIST\n",
    "mnist_trainset  = DigitsDataset(data_path=\"data/mixed_digit_dataset/MNIST\", channels=1, percent=percent, train=True,  transform=transform_mnist)\n",
    "mnist_testset   = DigitsDataset(data_path=\"data/mixed_digit_dataset/MNIST\", channels=1, percent=0.1, train=False, transform=transform_mnist)\n",
    "\n",
    "# SVHN\n",
    "svhn_trainset  = DigitsDataset(data_path='data/mixed_digit_dataset/SVHN', channels=3, percent=percent,  train=True,  transform=transform_svhn)\n",
    "svhn_testset   = DigitsDataset(data_path='data/mixed_digit_dataset/SVHN', channels=3, percent=0.1,  train=False, transform=transform_svhn)\n",
    "\n",
    "# USPS\n",
    "usps_trainset  = DigitsDataset(data_path='data/mixed_digit_dataset/USPS', channels=1, percent=percent,  train=True,  transform=transform_usps)\n",
    "usps_testset   = DigitsDataset(data_path='data/mixed_digit_dataset/USPS', channels=1, percent=0.1,  train=False, transform=transform_usps)\n",
    "\n",
    "# Synth Digits\n",
    "synth_trainset = DigitsDataset(data_path='data/mixed_digit_dataset/SynthDigits/', channels=3, percent=percent,  train=True,  transform=transform_synth)\n",
    "synth_testset = DigitsDataset(data_path='data/mixed_digit_dataset/SynthDigits/', channels=3, percent=0.1,  train=False, transform=transform_synth)\n",
    "\n",
    "# MNIST-M\n",
    "mnistm_trainset = DigitsDataset(data_path='data/mixed_digit_dataset/MNIST_M/', channels=3, percent=percent,  train=True,  transform=transform_mnistm)\n",
    "mnistm_testset  = DigitsDataset(data_path='data/mixed_digit_dataset/MNIST_M/', channels=3, percent=0.1,  train=False, transform=transform_mnistm)\n",
    "\n",
    "\n",
    "trainsets = [mnist_trainset, svhn_trainset, usps_trainset, synth_trainset, mnistm_trainset]\n",
    "testsets  = [mnist_testset, svhn_testset, usps_testset, synth_testset, mnistm_testset]\n",
    "\n",
    "datasets_name = ['MNIST', 'SVHN', 'USPS', 'SynthDigits', 'MNIST-M']\n",
    "datasets_client_index = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196df99-d133-4823-8e56-3cce499cf25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clients_indexset = [ i for i in range(args.K)]\n",
    "clientnumbers_per_dataset = int(args.K/len(datasets_name))\n",
    "np.random.seed(args.seed)\n",
    "for i in range(len(datasets_name)):\n",
    "    datasets_client_index[datasets_name[i]] = list(np.random.choice(clients_indexset, clientnumbers_per_dataset, replace=False))\n",
    "    clients_indexset = list(set(clients_indexset) - set(datasets_client_index[datasets_name[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17495e-1a51-48f9-80c5-3b35b3b25c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform partition\n",
    "labeldir_parts = []\n",
    "labeldir_part_dfs = []\n",
    "for dataset_name, trainset in zip(datasets_name, trainsets):\n",
    "    dataset_client_num = len(datasets_client_index[dataset_name])\n",
    "    # labeldir_part = FMNISTPartitioner(trainset.targets, \n",
    "    #                                             num_clients=dataset_client_num,\n",
    "    #                                             partition=\"iid\",\n",
    "    #                                             seed=1)\n",
    "    labeldir_part = FMNISTPartitioner(trainset.targets,  \n",
    "                                               num_clients=dataset_client_num,\n",
    "                                               partition=\"noniid-#label\", \n",
    "                                               major_classes_num=2,\n",
    "                                               seed=1)\n",
    "    \n",
    "    # labeldir_part = FMNISTPartitioner(trainset.targets, \n",
    "    #                                     num_clients=dataset_client_num,\n",
    "    #                                     partition=\"noniid-labeldir\", \n",
    "    #                                     dir_alpha=0.5,\n",
    "    #                                     seed=3)\n",
    "    \n",
    "    # generate partition report\n",
    "    csv_file = \"data/fmnist/fmnist_noniid_labeldir_clients_10.csv\"\n",
    "    partition_report(trainset.targets, labeldir_part.client_dict, \n",
    "                     class_num=num_classes, \n",
    "                     verbose=False, file=csv_file)\n",
    "\n",
    "    labeldir_part_df = pd.read_csv(csv_file,header=1)\n",
    "    labeldir_part_df = labeldir_part_df.set_index('client')\n",
    "    for col in col_names:\n",
    "        labeldir_part_df[col] = (labeldir_part_df[col] * labeldir_part_df['Amount']).astype(int)\n",
    "        \n",
    "    labeldir_parts.append(labeldir_part)\n",
    "    labeldir_part_dfs.append(labeldir_part_df)\n",
    "\n",
    "labeldir_part_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e8e14-06ca-4a0b-a927-6614aa77aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_list =  [transform_mnist, transform_svhn, transform_usps, transform_synth, transform_mnistm]\n",
    "channels_list = [1, 3, 1, 3, 3]\n",
    "path_list = [\"data/mixed_digit_dataset/MNIST\", \n",
    "            'data/mixed_digit_dataset/SVHN',\n",
    "            'data/mixed_digit_dataset/USPS',\n",
    "            'data/mixed_digit_dataset/SynthDigits/',\n",
    "            'data/mixed_digit_dataset/MNIST_M/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a913ae-fa85-4585-aa27-73275d0282bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_client_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d461cf-aed1-4294-90ec-a60b13a68f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_dataset_index = {i:[] for i in range(args.K)}\n",
    "for i in range(args.K):\n",
    "    for dataset_name in datasets_client_index.keys():\n",
    "        if i in datasets_client_index[dataset_name]:\n",
    "            clients_dataset_index[i] = datasets_name.index(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188e927-252e-4417-8b1e-68e92f3d77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_dataset_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221df82-ef4c-444b-b79c-84791ec32918",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_sample_rate = args.trainset_sample_rate\n",
    "rare_class_nums = 0\n",
    "dict_users_train = {i: [] for i in range(args.K)}\n",
    "for index, trainset in enumerate(trainsets):\n",
    "    dict_users_train_part = trainset_sampling_mixed_digit(args, datasets_client_index[datasets_name[index]], trainset, trainset_sample_rate, rare_class_nums, labeldir_parts[index])\n",
    "    for key in dict_users_train_part.keys():\n",
    "        dict_users_train[key] = dict_users_train_part[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486d4f8-c689-4dac-bb14-96e180cfe9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_number = {j:{}  for j in range(args.K)}\n",
    "\n",
    "for i in range(args.K):\n",
    "    training_number[i] = {j: 0 for  j in range(num_classes)}\n",
    "    label_class = set (np.array(trainset.targets)[list(dict_users_train[i])].tolist())\n",
    "    #print(list(label_class))\n",
    "    for k in label_class:\n",
    "        training_number[i][k] = list(np.array(trainset.targets)[list(dict_users_train[i])]).count(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747bcbe-2a18-4608-a6c0-33abdf67e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_number=[]\n",
    "df_training_number=pd.DataFrame(df_training_number)\n",
    "for i in range(args.K):\n",
    "    temp = pd.Series(training_number[i])\n",
    "    df_training_number[i]= temp\n",
    "    \n",
    "df_training_number['Col_sum'] = df_training_number.apply(lambda x: x.sum(), axis=1)\n",
    "df_training_number.loc['Row_sum'] = df_training_number.apply(lambda x: x.sum())\n",
    "\n",
    "df_training_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76465f-5f17-463a-ba50-d7dc416f8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "for index, testset in enumerate(testsets):\n",
    "        dict_test[datasets_name[index]] = testset_sampling_mixed_digit(args, testset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd748b-2541-4076-b17e-18d823e0a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_datasets_varify = {'MNIST':{i: [] for i in range(args.num_classes)}, \n",
    "                        'SVHN':{i: [] for i in range(args.num_classes)}, \n",
    "                        'USPS':{i: [] for i in range(args.num_classes)}, \n",
    "                        'SynthDigits':{i: [] for i in range(args.num_classes)}, \n",
    "                        'MNIST-M':{i: [] for i in range(args.num_classes)}}\n",
    "dict_varify = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "for index, testset in enumerate(testsets):\n",
    "    dict_varify[datasets_name[index]] = testset_sampling_mixed_digit(args, testset, 10)\n",
    "    \n",
    "for index, testset in enumerate(testsets):\n",
    "    for i in dict_varify[datasets_name[index]]: \n",
    "        for c in range(args.num_classes):\n",
    "            if np.array(testset.targets)[i] == c: \n",
    "                dict_datasets_varify[datasets_name[index]][c].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76493a-8ba5-4e1f-9f22-5a3569287e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_test['MNIST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ce0a8-a51e-4c5b-81eb-7cf50f38c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = []\n",
    "for i in range(args.K):\n",
    "    if df_training_number.loc['Row_sum'][i] % args.B == 1:\n",
    "        a_list.extend([i])\n",
    "print(a_list)\n",
    "for k in a_list:\n",
    "    dict_users_train[k] = dict_users_train[k] - {list(dict_users_train[k])[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe702ef-2c87-4ad6-b333-b49ee194214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  baseline----> iid setting with fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610ac48-32a3-4014-a571-8641bcaefbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_iid = DigitsDataset_IID(path_list, channels_list, transform_list= transform_list, train=True)\n",
    "#testset_iid = DigitsDataset_IID(path_list, channels_list, transform_list= transform_list, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7212b0-7a9d-48d9-b81b-988c07a0e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform partition\n",
    "labeldir_parts_iid = []\n",
    "labeldir_part_dfs_iid = []\n",
    "\n",
    "labeldir_part_iid = FMNISTPartitioner(trainset_iid.targets, \n",
    "                                            num_clients=args.K,\n",
    "                                            partition=\"iid\",\n",
    "                                            seed=1)\n",
    "# labeldir_part = FMNISTPartitioner(trainset.targets,  \n",
    "#                                            num_clients=dataset_client_num,\n",
    "#                                            partition=\"noniid-#label\", \n",
    "#                                            major_classes_num=5,\n",
    "#                                            seed=args.seed)\n",
    "# generate partition report\n",
    "csv_file = \"data/fmnist/fmnist_noniid_labeldir_clients_10.csv\"\n",
    "partition_report(trainset_iid.targets, labeldir_part_iid.client_dict, \n",
    "                 class_num=num_classes, \n",
    "                 verbose=False, file=csv_file)\n",
    "\n",
    "labeldir_part_df_iid = pd.read_csv(csv_file,header=1)\n",
    "labeldir_part_df_iid = labeldir_part_df_iid.set_index('client')\n",
    "for col in col_names:\n",
    "    labeldir_part_df_iid[col] = (labeldir_part_df_iid[col] * labeldir_part_df_iid['Amount']).astype(int)\n",
    "\n",
    "# labeldir_parts_iid.append(labeldir_part_iid)\n",
    "# labeldir_part_dfs_iid.append(labeldir_part_df_iid)\n",
    "labeldir_part_df_iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d333acb-48ed-4784-8b0e-8e5efc0b8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_users_train_iid = trainset_sampling_label(args, trainset_iid, trainset_sample_rate, rare_class_nums, labeldir_part_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835d1ee-0a2b-4b44-b78d-c7e2e4e34f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset_iid.targets[list(dict_users_train_iid[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe06a8-661e-4aa1-9c03-e6f99b9a57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_users_train_iid = trainset_sampling_label(args, trainset_iid, trainset_sample_rate, rare_class_nums, labeldir_part_iid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869aef2-0d8e-4477-a6ce-b3cc81f88fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_dataset_index_iid = {i:[] for i in range(args.K)}\n",
    "for i in range(args.K):\n",
    "        clients_dataset_index_iid[i] = [k for k in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc2ee0-d5bc-4fc6-9cc6-57bb34f1fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "specf_model = model.DigitModel().to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189d5ce-d699-45f1-98d7-73569995f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iid-fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20b5e8-6c06-4f33-b437-86281c184175",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_iid = server.Server(args, specf_model, trainset_iid, dict_users_train_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ff6d3-de89-414f-bd21-296f43faf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_model_iid, similarity_dict_iid, client_models_iid, loss_dict_iid, clients_index_iid, acc_list_iid = server_iid.fedavg_joint_update(testsets, dict_test, fedbn=True, similarity=True, test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_list_iid = torch.load(\"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/acc_list_iid_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_model_iid = server_iid.nn\n",
    "    client_models_iid = server_iid.nns\n",
    "    path_iid_fedavg = \"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/global_model_iid-fedavg_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    global_model_iid.load_state_dict(torch.load(path_iid_fedavg))\n",
    "    for i in range(args.K):\n",
    "        path_iid_fedavg = \"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/client{}_model_iid-fedavg_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "        client_models_iid[i].load_state_dict(torch.load(path_iid_fedavg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c402f-178e-4d5a-8aec-39c1b2a2bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dict_iid,\"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/similarity_dict_iid_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_list_iid,\"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/acc_list_iid_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_iid_fedavg = \"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/global_model_iid-fedavg_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    torch.save(global_model_iid.state_dict(), path_iid_fedavg)\n",
    "    # for i in range(args.K):\n",
    "    #     path_iid_fedavg = \"results/Test/feature skew/mixed_digit/iid-fedavg/seed{}/client{}_model_iid-fedavg_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_models_iid[i].state_dict(), path_iid_fedavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8bfaf-c116-444d-be8e-944de07fac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_iid = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_giid = 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    giid,_ = test_on_globaldataset_mixed_digit(args, global_model_iid, testset, dict_test[datasets_name[index]])\n",
    "    d_iid[datasets_name[index]] = giid\n",
    "    mean_giid += giid/5\n",
    "d_iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596ea98-8b2b-4b4f-b75e-860259f3ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dict_iid,clients_index_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aec58e-2013-4c1d-9a4d-33bea7b5df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_iid\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c98e79-06c1-486c-a674-989dd942646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9466e20-8d71-46aa-98b7-81874873153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_fedavg =  server.Server(args, specf_model, trainsets, dict_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78f871-f8be-4670-810d-ee2156489b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_model1, similarity_dict1, client_models1, loss_dict1, clients_index1, acc_list1 = server_fedavg.fedbn(testsets, dict_test,clients_dataset_index, similarity=True,fe_optimizer_name = \"fedavg\", test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_list1 = torch.load(\"results/Test/feature skew/mixed_digit/fedavg/seed{}/acc_list1_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_model1 = server_fedavg.nn\n",
    "    client_models1 = server_fedavg.nns\n",
    "    path_fedavg = \"results/Test/feature skew/mixed_digit/fedavg/seed{}/global_model_fedavg_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    global_model1.load_state_dict(torch.load(path_fedavg))\n",
    "    for i in range(args.K):\n",
    "        path_fedavg = \"results/Test/feature skew/mixed_digit/fedavg/seed{}/client{}_model_fedavg_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "        client_models1[i].load_state_dict(torch.load(path_fedavg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e147267-ade7-4604-9318-dc1db32c29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dict1,\"results/Test/feature skew/mixed_digit/fedavg/seed{}/similarity_dict1_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_list1,\"results/Test/feature skew/mixed_digit/fedavg/seed{}/acc_list1_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_fedavg = \"results/Test/feature skew/mixed_digit/fedavg/seed{}/global_model_fedavg_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    torch.save(global_model1.state_dict(), path_fedavg)\n",
    "    # for i in range(args.K):\n",
    "    #     path_fedavg = \"results/Test/feature skew/mixed_digit/fedavg/seed{}/client{}_model_fedavg_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_models1[i].state_dict(), path_fedavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95e2e9-2609-41f1-9c21-db9f1b92ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_g1 = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_g1 = 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    #print(datasets_name[index])\n",
    "    g1,_ = test_on_globaldataset_mixed_digit(args, global_model1, testset, dict_test[datasets_name[index]])\n",
    "    d_g1[datasets_name[index]]  = g1 \n",
    "    mean_g1 += g1/len(testsets)\n",
    "d_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376e58c-1c40-4dd7-96b8-ec33bd0aa25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630a71b-a443-4854-ac75-a87c1b0e24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dict1,clients_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a67abc-cced-456f-b9c9-eb0c1ad30baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_fedavg\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d684d6-4381-4faa-b657-f6e0c7e052bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fedprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359b5b2-4b0d-40fb-a24d-d94ae60e9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_fedprox_joint = server.Server(args, specf_model, trainsets, dict_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31f397-dad7-42bc-99fc-f909de95a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_modelp, similarity_dictp, client_modelsp, loss_dictp, clients_indexp, acc_listp = server_fedprox_joint.fedbn(testsets, dict_test,clients_dataset_index, similarity=True,fe_optimizer_name = \"fedprox\", test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_listp = torch.load(\"results/Test/feature skew/mixed_digit/fedprox/seed{}/acc_listp_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_modelp = server_fedprox_joint.nn\n",
    "    client_modelsp = server_fedprox_joint.nns\n",
    "    path_fedprox = \"results/Test/feature skew/mixed_digit/fedprox/seed{}/global_model_fedprox_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    global_modelp.load_state_dict(torch.load(path_fedprox))\n",
    "    for i in range(args.K):\n",
    "        path_fedprox = \"results/Test/feature skew/mixed_digit/fedprox/seed{}/client{}_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "        client_modelsp[i].load_state_dict(torch.load(path_fedprox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d0a88-b245-43b9-9220-32c3b2937947",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dictp,\"results/Test/feature skew/mixed_digit/fedprox/seed{}/similarity_dictp_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_listp,\"results/Test/feature skew/mixed_digit/fedprox/seed{}/acc_listp_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_fedprox = \"results/Test/feature skew/mixed_digit/fedprox/seed{}/global_model_fedprox_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    torch.save(global_modelp.state_dict(), path_fedprox)\n",
    "    # for i in range(args.K):\n",
    "    #     path_fedprox = \"results/Test/feature skew/mixed_digit/fedprox/seed{}/client{}_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_modelsp[i].state_dict(), path_fedprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691c981-a822-4d51-b8fc-0fad0b0f6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gp = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_gp= 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    gp,_ = test_on_globaldataset_mixed_digit(args, global_modelp, testset, dict_test[datasets_name[index]])\n",
    "    d_gp[datasets_name[index]] = gp \n",
    "    mean_gp += gp/5\n",
    "d_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a690e2-f304-4d9b-84e9-da49abff580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68a091-43d8-42bd-8592-750f27f22ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dictp,clients_indexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6fb68-1e53-4c46-ba0b-3a32e3f84f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_fedprox_joint\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d353d6-5ccd-4eb6-a0fa-d58e10706114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feddyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8c6e7-5cbc-40ce-a593-7fcd100054cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_feddyn = server.Server(args, specf_model, trainsets, dict_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d7bb7-64ed-4af4-a8c9-9f857a84d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_modeldyn, similarity_dictdyn, client_modelsdyn, loss_dictdyn, clients_indexdyn, acc_listdyn = server_feddyn.fedbn(testsets, dict_test,clients_dataset_index, similarity=True,fe_optimizer_name = \"feddyn\", test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_listdyn = torch.load(\"results/Test/feature skew/mixed_digit/feddyn/seed{}/acc_listdyn_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_modeldyn = server_feddyn.nn\n",
    "    client_modelsdyn = server_feddyn.nns\n",
    "    path_feddyn = \"results/Test/feature skew/mixed_digit/feddyn/seed{}/global_model_feddyn_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    global_modeldyn.load_state_dict(torch.load(path_feddyn))\n",
    "    for i in range(args.K):\n",
    "        path_feddyn = \"results/Test/feature skew/mixed_digit/feddyn/seed{}/client{}_model_feddyn_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "        client_modelsdyn[i].load_state_dict(torch.load(path_feddyn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b7636-4175-45cf-83a9-65d5f07a8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dictdyn,\"results/Test/feature skew/mixed_digit/feddyn/seed{}/similarity_dictdyn_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_listdyn,\"results/Test/feature skew/mixed_digit/feddyn/seed{}/acc_listdyn_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_feddyn = \"results/Test/feature skew/mixed_digit/feddyn/seed{}/global_model_feddyn_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    torch.save(global_modeldyn.state_dict(), path_feddyn)\n",
    "    # for i in range(args.K):\n",
    "    #     path_feddyn = \"results/Test/feature skew/mixed_digit/feddyn/seed{}/client{}_model_feddyn_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_modelsdyn[i].state_dict(), path_feddyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917d874-6e8e-40ce-96e1-79888732a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gdyn ={'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_gdyn = 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    gdyn,_ = test_on_globaldataset_mixed_digit(args, global_modeldyn, testset, dict_test[datasets_name[index]])\n",
    "    d_gdyn[datasets_name[index]] = gdyn\n",
    "    mean_gdyn += gdyn/len(testsets)\n",
    "d_gdyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d86092-3285-4bba-8c71-4cc31f976f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gdyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1fe73-b3bd-42c2-b4d8-c47c088244bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dictdyn,clients_indexdyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d290c7-dba7-4d46-9295-7c4cc88fcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_feddyn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627b6cc-0231-43f3-8c16-5554b6046532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2000a-4fb7-40f7-a6f5-b9525305cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_moon = server.Server(args, specf_model, trainsets, dict_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c2c68-17d5-4a43-a13b-f50ce896ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_modelm, similarity_dictm, client_modelsm, loss_dictm, clients_indexm, acc_listm = server_moon.fedbn(testsets, dict_test,clients_dataset_index,similarity=True, fe_optimizer_name = \"moon\", test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_listm = torch.load(\"results/Test/feature skew/mixed_digit/moon/seed{}/acc_listm_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_modelm = server_moon.nn\n",
    "    client_modelsm = server_moon.nns\n",
    "    path_moon = \"results/Test/feature skew/mixed_digit/moon/seed{}/global_model_moon_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    global_modelm.load_state_dict(torch.load(path_moon))\n",
    "    for i in range(args.K):\n",
    "        path_moon = \"results/Test/feature skew/mixed_digit/moon/seed{}/client{}_model_moon_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "        client_modelsm[i].load_state_dict(torch.load(path_moon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f18dc-6f15-4e3f-9611-e364eedaab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dictm,\"results/Test/feature skew/mixed_digit/moon/seed{}/similarity_dictm_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_listm,\"results/Test/feature skew/mixed_digit/moon/seed{}/acc_listm_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_moon = \"results/Test/feature skew/mixed_digit/moon/seed{}/global_model_moon_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    torch.save(global_modelm.state_dict(), path_moon)\n",
    "    # for i in range(args.K):\n",
    "    #     path_moon = \"results/Test/feature skew/mixed_digit/moon/seed{}/client{}_model_moon_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_modelsm[i].state_dict(), path_moon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44176c20-03ea-4ba1-8f48-2627f508222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gm = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_gm = 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    gm,_ = test_on_globaldataset_mixed_digit(args, global_modelm, testset, dict_test[datasets_name[index]])\n",
    "    d_gm[datasets_name[index]] = gm\n",
    "    mean_gm += gm/5\n",
    "d_gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31735cc7-133c-4005-b124-a8f4e6c30d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c42ec-50ec-46be-ad06-6aa034156a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dictm,clients_indexm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad78adc-1b12-4d64-82ba-6dd00b8f0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_moon\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c034-7e9a-4df0-a6b2-257118563b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fedproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb9633-93f0-4866-a190-9f8fc16938d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_fedproc = server.Server(args, specf_model, trainsets, dict_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a510af0-ed8a-469c-a57b-503f7ab739a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_modelproc, similarity_dictproc, client_modelsproc, loss_dictproc, clients_indexproc, acc_listproc= server_fedproc.fedbn(testsets, dict_test,clients_dataset_index, similarity=True,fe_optimizer_name = \"fedproc\", test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_listproc = torch.load(\"results/Test/feature skew/mixed_digit/fedproc/seed{}/acc_listproc_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_modelproc = server_fedproc.nn\n",
    "    client_modelsproc = server_fedproc.nns\n",
    "    path_fedproc = \"results/Test/feature skew/mixed_digit/fedproc/seed{}/global_model_fedproc_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    global_modelproc.load_state_dict(torch.load(path_fedproc))\n",
    "    for i in range(args.K):\n",
    "        path_fedproc = \"results/Test/feature skew/mixed_digit/fedproc/seed{}/client{}_model_fedproc_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "        client_modelsproc[i].load_state_dict(torch.load(path_fedproc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92968c83-9c3e-4a4c-b67b-fc37fd770f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dictproc,\"results/Test/feature skew/mixed_digit/fedproc/seed{}/similarity_dictproc_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_listproc,\"results/Test/feature skew/mixed_digit/fedproc/seed{}/acc_listproc_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_fedproc = \"results/Test/feature skew/mixed_digit/fedproc/seed{}/global_model_fedproc_{}E_{}class.pt\".format(args.seed,args.E,C)\n",
    "    torch.save(global_modelproc.state_dict(), path_fedproc)\n",
    "    # for i in range(args.K):\n",
    "    #     path_fedproc = \"results/Test/feature skew/mixed_digit/fedproc/seed{}/client{}_model_fedproc_{}E_{}class.pt\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_modelsproc[i].state_dict(), path_fedproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb56cbf-9fea-4773-b928-07a6ba7d6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gproc = {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_gproc = 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    gproc,_ = test_on_globaldataset_mixed_digit(args, global_modelproc, testset, dict_test[datasets_name[index]])\n",
    "    d_gproc[datasets_name[index]] = gproc\n",
    "    mean_gproc += gproc/5\n",
    "d_gproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb55e22-2507-470e-b387-81d0e944ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db6bfe-d5f2-4da1-a405-782f74541c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dictproc,clients_indexproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ae8d8-0f7d-4be4-8886-58d4b8fda1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_fedproc\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8d590-3f71-4b29-b587-894ae1d7c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fedfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90083b36-3d25-4c36-b195-f665a68fbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_fedfa =  server.Server(args, specf_model, trainsets, dict_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45c01b-d2a8-4744-8c41-9be17375fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    global_modelfa, similarity_dictfa, client_modelsfa, loss_dictfa, clients_indexfa, acc_listfa = server_fedfa.fedbn(testsets, dict_test,clients_dataset_index, similarity=True,fe_optimizer_name = \"fedfa\", test_global_model_accuracy = True)\n",
    "else:\n",
    "    acc_listfa = torch.load(\"results/Test/feature skew/mixed_digit/fedfa/seed{}/acc_listfa_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    global_modelfa = server_feature.nn\n",
    "    client_modelsfa = server_feature.nns\n",
    "    path_fedfa = \"results/Test/feature skew/mixed_digit/fedfa/seed{}/global_model_fedfa_{}E_{}class\".format(args.seed,args.E,C)\n",
    "    global_modelfa.load_state_dict(torch.load(path_fedfa))\n",
    "    for i in range(args.K):\n",
    "        path_fedfa = \"results/Test/feature skew/mixed_digit/fedfa/seed{}/client{}_model_fedfa_{}E_{}class\".format(args.seed,i,args.E,C)\n",
    "        client_modelsfa[i].load_state_dict(torch.load(path_fedfa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75340b6e-3654-45ad-8585-04413a3ba668",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models:\n",
    "    if similarity:\n",
    "        torch.save(similarity_dictfa,\"results/Test/feature skew/mixed_digit/fedfa/seed{}/similarity_dictfa_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    torch.save(acc_listfa,\"results/Test/feature skew/mixed_digit/fedfa/seed{}/acc_listfa_{}E_{}class.pt\".format(args.seed,args.E,C))\n",
    "    path_fedfa = \"results/Test/feature skew/mixed_digit/fedfa/seed{}/global_model_fedfa_{}E_{}class\".format(args.seed,args.E,C)\n",
    "    torch.save(global_modelfa.state_dict(), path_fedfa)\n",
    "    # for i in range(args.K):\n",
    "    #     path_fedfa = \"results/Test/feature skew/mixed_digit/fedfa/seed{}/client{}_model_fedfa_{}E_{}class\".format(args.seed,i,args.E,C)\n",
    "    #     torch.save(client_modelsfa[i].state_dict(), path_fedfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0530e-c6e3-4e9f-91c0-e7297114acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gfa =  {'MNIST':[], 'SVHN':[], 'USPS':[], 'SynthDigits':[], 'MNIST-M':[]}\n",
    "mean_gfa = 0.0\n",
    "for index, testset in enumerate(testsets):\n",
    "    gfa,_ = test_on_globaldataset_mixed_digit(args, global_modelfa, testset, dict_test[datasets_name[index]])\n",
    "    d_gfa[datasets_name[index]]  = gfa \n",
    "    mean_gfa += gfa/5\n",
    "d_gfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71d124-9c34-45dc-ad36-7c62e9674bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb926ca-7c1b-4663-9d4a-3bafb4082b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_model:\n",
    "    train_loss_show(args, loss_dictfa,clients_indexfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f1ad0-37c6-4775-9403-78f31c3ec135",
   "metadata": {},
   "outputs": [],
   "source": [
    "del server_fedfa\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
